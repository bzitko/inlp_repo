{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "download_name = \"dataset.zip\"\n",
    "if not os.path.exists(download_name):\n",
    "    import requests\n",
    "    response = requests.get(f\"https://raw.githubusercontent.com/bzitko/inlp_repo/main/labs/opj_v07_analiza_sentimenta/{download_name}\")\n",
    "    with open(download_name, \"wb\") as fp:\n",
    "        fp.write(response.content)\n",
    "    response.close()\n",
    "\n",
    "if not os.path.exists(\"imdb1\"):\n",
    "    from zipfile import ZipFile\n",
    "    with ZipFile(download_name) as zf:\n",
    "        zf.extractall(path=\".\")\n",
    "\n",
    "\n",
    "name = \"opj_v07_test.py\"\n",
    "if not os.path.exists(name):\n",
    "    response = requests.get(f\"https://raw.githubusercontent.com/bzitko/inlp_repo/main/labs/opj_v07_analiza_sentimenta/{name}\")\n",
    "    with open(name, \"wb\") as fp:\n",
    "        fp.write(response.content)\n",
    "    response.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Analiza sentimenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "from opj_v07_test import *\n",
    "\n",
    "DATA_PATH = 'imdb1/'\n",
    "STOPWORD_FILENAME = 'english.stop'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Izgradnja modela dokumenata\n",
    "\n",
    "Funkcija **make_datasets()** ima sljedeće ulazne i izlazne parametre\n",
    "* ulaz:\n",
    "    * **data_path** putanja do datoteka\n",
    "* izlaz:\n",
    "    * lista oblika  \n",
    "\n",
    "<pre>\n",
    "0: train: pos: [filename, filename, ...]\n",
    "          neg: [filename, filename, ...]\n",
    "   test:  pos:  [filename, filename, ...]  \n",
    "          neg:  [filename, filename, ...]  \n",
    "1: train: pos: [filename, filename, ...]  \n",
    "          neg: [filename, filename, ...]  \n",
    "   test:  pos:  [filename, filename, ...]  \n",
    "          neg:  [filename, filename, ...]  \n",
    "...  \n",
    "...\n",
    "</pre>\n",
    "\n",
    "Svaki element liste se zove \"preklop\" (engl. fold) i sastoji se od dokumenata za treniranje i testiranje. \n",
    "Preklop je rječnik sa dva ključa \"train\" i \"test\" čije su vrijednosti rječnik s dva ključa \"pos\" i \"neg\" čije su vrijednosti lista datoteka koje su \"pos\" ili \"neg\" kritike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_datasets(data_path, numfolds = 10):\n",
    "    \"\"\"\n",
    "    ulaz:\n",
    "    -data_path: putanja do datoteka\n",
    "    izlaz:\n",
    "    -lista oblika\n",
    "    0: train: pos: [filename, filename, ...]\n",
    "              neg: [filename, filename, ...]\n",
    "       test: pos:  [filename, filename, ...]\n",
    "             neg:  [filename, filename, ...]\n",
    "    1: train: pos: [filename, filename, ...]\n",
    "              neg: [filename, filename, ...]\n",
    "       test: pos:  [filename, filename, ...]\n",
    "             neg:  [filename, filename, ...]\n",
    "    ...\n",
    "    ...\n",
    "    Svaki element liste je rječnik sa dva ključa \"train\" i \"test\"\n",
    "    čije su vrijednosti rječnik s dva ključa \"pos\" i \"neg\" čije su\n",
    "    vrijednosti lista datoteka koje su \"pos\" ili \"neg\" kritike\n",
    "    \"\"\"\n",
    "    klasses = [klass for klass in os.listdir(data_path) if not klass.startswith('.')]\n",
    "    datasets = []\n",
    "    filenames = {klass: sorted(os.listdir(data_path + klass + '/')) for klass in klasses}\n",
    "    for fold in range(numfolds):\n",
    "        trains = {klass: [] for klass in klasses}\n",
    "        tests = {klass: [] for klass in klasses}\n",
    "        for klass in klasses:\n",
    "            for filename in filenames[klass]:\n",
    "                if filename[2] == str(fold):\n",
    "                    tests[klass].append(data_path + klass + '/' + filename)\n",
    "                else:\n",
    "                    trains[klass].append(data_path + klass + '/' + filename)\n",
    "        datasets.append({'train': trains, 'test': tests})\n",
    "    return datasets\n",
    "\n",
    "datasets = make_datasets(DATA_PATH)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Učitavanje stop riječi i dokumenata\n",
    "\n",
    "Napravi funkciju **read_stopwords()** po sljedećim ulaznim i izlaznim podacima\n",
    "* ulaz:\n",
    "    * **filename** datoteka\n",
    "* izlaz:\n",
    "    * skup stop riječi iz datoteke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stopwords(filename):\n",
    "    \"\"\"\n",
    "    ulaz:\n",
    "    -filename: datoteka\n",
    "\n",
    "    izlaz:\n",
    "    -skup stop riječi iz datoteke\n",
    "    \"\"\"\n",
    "    return\n",
    "\n",
    "testname(read_stopwords)\n",
    "stopwords = test(read_stopwords, (STOPWORD_FILENAME,), {'nine', 'willing', 'inc', 'because', 'edu', 'whenever', 'well', 'hence', 'may', 'seven', 'sometime', 'becomes', 'among', 'had', 'lest', 'containing', 'yourself', 'of', 'theirs', \"i'll\", 'said', 'down', 'p', 'hereby', 'sub', 'then', 'there', 'qv', 'nothing', 'is', 'tries', 'new', 'x', 'everywhere', 'otherwise', 'com', 'presumably', 'amongst', 'become', 'were', 'they', 'her', 'also', 'hers', 'second', 'tried', 'gone', 'two', 'wants', 'above', 'although', 'much', 'rd', 'f', 'was', 'have', 'has', 'just', 'thorough', 'took', 'particular', 'together', 'up', 'became', 'mean', 'anybody', \"they're\", 'former', 'only', 'follows', 'right', 'think', 'especially', 'we', 'not', 'concerning', 'which', 'despite', 'tends', 'course', \"aren't\", 'used', 'cant', 'formerly', 'anyways', 'usually', 'your', 'goes', 'having', 'here', 'nor', \"what's\", \"c's\", 'reasonably', 'a', 'see', 'theres', 'meanwhile', \"we'll\", 'how', \"you'd\", 'third', 'contain', 'brief', 'becoming', 'asking', 'r', 'liked', 'novel', 'me', 'for', 'its', 'unfortunately', 'elsewhere', 'uses', 'are', 'whereupon', 'overall', 'know', 'consider', 'help', 'uucp', 'furthermore', 'enough', 'according', 'anyway', 'latter', 'far', 'truly', \"we've\", 'definitely', 'keep', 'yet', 'mostly', 'behind', 'un', 'serious', 'doing', 'probably', 'though', 'what', 'must', 'our', 'say', 'contains', 'upon', 'provides', 'more', \"don't\", 'per', \"t's\", 'thereupon', 'unlikely', 'going', 'always', 'anything', 'currently', 'still', 'associated', 'obviously', 'and', 'very', 'described', 'better', 'do', \"you'll\", 'him', 'looks', 'hardly', \"haven't\", 'k', \"they've\", 'seriously', 'thereafter', 'nd', 'particularly', 'be', 'whom', 'out', 'like', 'welcome', 'able', 'go', 'gives', 'seeming', 'trying', 'anyone', 'each', 'inner', 'namely', 'he', 'to', 'thank', 'beyond', 'herein', 'm', 'useful', 'various', 'wherever', 'thus', 'l', 'ask', 'within', 'merely', \"shouldn't\", \"that's\", 'sometimes', \"they'll\", 'wherein', \"where's\", \"ain't\", 'gotten', 'somehow', 'ignored', 'therein', 'ever', 'yours', 'other', 'let', 'certain', 'changes', 'whereby', 'hither', 'allow', 'could', 'respectively', 'inward', 'wonder', 'under', 'someone', 'therefore', 'necessary', 'etc', 'in', 'least', 'awfully', 'relatively', 'shall', 'corresponding', 'should', 'appear', 'need', 'whither', 'non', 'looking', 'get', 'v', 'sorry', \"wouldn't\", 'whereas', 'lately', 'n', 'says', 'wish', 'soon', 'six', 'himself', 'entirely', 'got', \"i'd\", 'even', 'example', 'e', 'self', 'vs', 'several', 'considering', 'however', 'such', 'why', 'getting', 'happens', 'okay', 'some', \"there's\", 'towards', \"hasn't\", 'sent', 'th', \"we're\", 'few', 'seemed', 'believe', 'four', 'b', 'whereafter', 'three', 'who', 'aside', 'does', 'or', 'actually', 'placed', \"doesn't\", 'further', 'latterly', 'once', 'maybe', 'one', 'herself', 'indicate', 'normally', 'regardless', 'ones', 'already', 'name', 'eight', 'so', 'their', 'ex', 'after', 'while', 'u', \"you've\", 'available', 'g', 'keeps', 'unto', 'afterwards', 'near', 'later', 'those', 'certainly', 'j', 'o', 'went', 'since', 'plus', 'whole', 'less', 'consequently', 'now', 'd', 'known', 'thanx', 'w', 'yes', 'oh', 'alone', 'my', 'us', 'neither', 'below', 'taken', 'hereafter', 'nowhere', 'whence', 'off', 'where', 'ourselves', 'regarding', 'given', 'by', 'except', 'immediate', \"isn't\", 'forth', 'over', 'else', 'try', 'everything', 'via', 'inasmuch', 'ours', 'toward', 'often', 'y', 'until', 'using', 'perhaps', 'them', 'about', 'seems', 'gets', 'specified', 'knows', 'seen', 'without', 'cannot', 'appropriate', 'every', 'clearly', 'both', 'downwards', \"a's\", 'everybody', 'accordingly', 'cause', 'old', 'with', 'tell', 'i', 'anyhow', 'besides', \"who's\", 'that', 'following', 'can', 'itself', 'q', 'thru', 'these', 'little', 'the', 'viz', 'hi', 'first', 'against', 'somewhat', \"weren't\", 'next', 'kept', 'thanks', 'sup', 'themselves', \"wasn't\", 'sure', \"he's\", 'done', 'allows', 'fifth', 'twice', 'across', 'apart', 'own', 'before', 'at', 'nearly', 'during', 'ltd', 'noone', 'causes', 'from', 'followed', 'away', \"couldn't\", 'best', 'last', 'most', 'nobody', 'almost', \"won't\", 'either', 'you', \"let's\", 'many', 'thence', 'hereupon', 'exactly', 'somewhere', 'please', 'anywhere', 'another', 'insofar', 'quite', 'way', 'appreciate', 'ok', 'regards', 'outside', 'five', 'between', 'ought', 'whoever', 'specify', 'would', 'throughout', 'instead', \"here's\", 'no', 'z', 'through', 'c', 'secondly', \"c'mon\", 'she', 'really', \"hadn't\", 'into', 'if', 'ie', 'want', 'same', 'whether', 'all', 'any', 'indicated', \"i'm\", 'zero', 's', 'will', 'thats', 'myself', 'possible', 'sensible', 'co', 'on', 'but', 'an', 'again', 'take', 'value', 'et', 'h', 'mainly', 'specifying', 'beforehand', 'as', 'around', 'thoroughly', 'beside', 'been', 'moreover', 'different', 'somebody', 'might', \"we'd\", 'likely', 'indeed', 'eg', \"they'd\", 'rather', 'nevertheless', 'others', \"can't\", \"you're\", 'selves', 'howbeit', 'hopefully', 'did', 'whose', 'when', 'came', 'his', 'never', 'whatever', 'along', \"it'll\", 'seeing', 'this', 'it', \"it'd\", 'am', 'come', 'unless', 'everyone', \"i've\", 'something', 'than', 'use', 're', 'hello', 'que', 'thereby', 'indicates', 'none', 't', 'seem', 'needs', 'yourselves', \"didn't\", 'onto', 'greetings', 'saying', 'comes', \"it's\", 'being', 'saw', 'look', 'too'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dokument\n",
    "\n",
    "Funkcija **read_document()** ima sljedeće ulazne i izlazne parametre\n",
    "* ulaz:\n",
    "    * **filename** datoteka dokumenta\n",
    "    * stopwords: skup stop riječi\n",
    "* izlaz:\n",
    "    * skup riječi iz datoteke koje nisu stop riječi\n",
    "    \n",
    "Ova funkcija će odvojiti riječi iz teksta datoteke po praznim redovima i razmacima (koristiti `split()` metodu stringa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_document(filename, stopwords = set()):\n",
    "    \"\"\"\n",
    "    ulaz:\n",
    "    -filename: datoteka dokumenta\n",
    "    -stopwords: skup stop riječi\n",
    "\n",
    "    izlaz:\n",
    "    -skup riječi iz datoteke koje nisu u stopwords\n",
    "    \"\"\"\n",
    "    return\n",
    "\n",
    "testname(read_document)\n",
    "_ = test(read_document, (datasets[0]['train']['pos'][0], ), set(['james', 'l', '.', 'brooks', ',', 'one', 'of', 'the', 'developers', 'of', 'the', 'simpsons', 'and', 'director', 'of', 'broadcast', 'news', ',', 'returns', 'to', 'the', 'big', 'screen', 'with', 'this', 'entertaining', ',', 'if', 'slightly', 'flawed', 'comedy', '.', 'nicholson', 'plays', 'melvin', 'udall', ',', 'probably', 'the', 'most', 'horrible', 'person', 'ever', 'on', 'the', 'screen', '.', \"he's\", 'racist', ',', 'homophobic', ',', 'and', 'never', 'has', 'a', 'good', 'word', 'to', 'say', 'to', 'anyone', '.', 'so', ',', 'nobody', 'talks', 'to', 'him', ',', 'except', 'waitress', 'carol', 'conelly', '(', 't', '.', 'v', 'sitcom', 'star', 'hunt', ',', 'who', 'was', 'last', 'seen', 'in', 'twister', ',', '1996', ')', '.', 'naturally', ',', 'udall', ',', 'conelly', 'and', 'gay', 'neighbor', 'simon', 'bishop', '(', 'kinnear', ')', 'who', 'nicholson', 'hates', ',', 'all', 'hit', 'it', 'off', 'in', 'the', 'end', '.', 'like', 'good', 'will', 'hunting', '(', '1997', ')', 'and', 'titanic', '(', '1997', ')', ',', 'even', 'though', 'the', 'outcome', 'is', 'completely', 'obvious', ',', 'as', 'good', 'as', 'it', 'gets', 'is', 'an', 'enjoyable', ',', 'funny', 'and', 'warm', 'comedy', '.', 'nicholson', 'is', 'hilarious', 'as', 'melvin', ',', 'churning', 'out', 'insults', 'with', 'superb', 'relish', '.', 'only', 'nicholson', 'could', 'get', 'away', 'with', 'the', 'lines', 'that', 'melvin', 'delivers', '.', 'hunt', 'is', 'also', 'good', 'as', 'waitress', 'carol', ',', 'and', 'easily', 'rises', 'to', 'the', 'challenge', 'of', 'nicholson', '.', \"there's\", 'also', '(', 'thankfully', ')', 'a', 'bit', 'of', 'chemistry', 'between', 'them', '.', 'kinnear', ',', 'as', 'the', 'gay', 'neighbor', ',', 'seems', 'to', 'have', 'a', 'slightly', 'underwritten', 'role', ',', \"he's\", 'more', 'of', 'a', 'plot', 'convience', 'than', 'a', 'character', '.', 'although', 'his', 'performance', 'is', 'good', ',', 'his', 'character', 'just', 'seems', 'to', 'exist', 'to', 'help', 'melvin', 'and', 'carol', 'come', 'together', '.', 'in', 'fact', ',', 'the', 'scene', 'stealer', 'is', \"simon's\", 'dog', ',', 'who', 'is', 'funnier', 'than', 'nicholson', '.', 'but', 'then', 'again', ',', 'pets', 'are', 'always', 'cute', 'on', 'screen', '.', 'providing', 'solid', 'support', 'is', 'cuba', 'gooding', ',', 'jnr', '(', 'jerry', 'maguire', ',', '1996', ')', 'and', 'yeardly', 'smith', '(', 'who', 'is', 'the', 'voice', 'of', 'lisa', 'simpsons', 'in', 'the', 'simpsons', ')', 'although', 'gooding', \"isn't\", 'as', 'good', 'as', 'is', 'character', 'in', 'maguire', ',', 'he', 'is', 'still', 'fun', '.', 'he', 'overacts', 'a', 'little', ',', 'but', 'not', 'so', 'much', 'as', 'to', 'be', 'annoying', '.', 'smith', 'is', 'also', 'good', ',', 'although', 'she', 'has', 'a', 'fairly', 'small', 'role', '.', 'even', 'director', 'lawrence', 'kasdan', '(', 'body', 'heat', ',', '1981', ')', 'makes', 'an', 'appearance', 'as', 'a', 'doctor', '.', 'but', 'this', 'is', 'primarily', 'nicholsons', 'film', ',', 'and', 'every', 'scene', \"he's\", 'in', ',', \"he's\", 'steals', 'it', '.', \"he's\", 'character', 'is', 'so', 'hateful', ',', 'though', ',', \"it's\", 'amazing', 'that', 'anyone', 'talks', 'to', 'him', 'at', 'all', ',', 'especially', 'carol', '.', 'and', 'this', 'is', 'the', 'films', 'main', 'problem', '.', \"it's\", 'totally', 'unbelievable', 'that', 'carol', 'would', 'ever', 'consider', 'liking', 'melvin', '.', 'she', \"doesn't\", 'fall', 'in', 'love', 'with', 'him', 'naturally', ',', 'the', 'film', 'forces', 'her', 'to', 'fall', 'in', 'love', 'with', 'him', '.', 'also', ',', 'melvins', 'character', 'seems', 'to', 'go', 'too', 'nice', ',', 'too', 'quickly', '.', 'i', 'would', 'doubt', 'anyone', 'with', 'a', 'character', 'like', 'melvins', 'would', 'be', 'able', 'to', 'turn', 'back', 'to', 'a', 'nice', ',', 'loving', 'person', '.', 'it', 'would', 'take', 'a', 'helluva', 'long', 'time', ',', 'much', 'longer', 'than', 'this', 'film', 'would', 'like', 'to', 'make', 'out', '.', 'brooks', 'direction', 'is', 'good', ',', 'though', ',', 'if', 'a', 'bit', 'average', ',', 'but', 'he', 'usually', 'manages', 'to', 'get', 'an', 'emotion', 'out', 'of', 'the', 'audience', '.', 'he', 'handles', 'the', 'comedy', 'scenes', 'better', 'than', 'the', 'sentimental', 'ones', '(', 'he', 'tends', 'to', 'pile', 'on', 'to', 'much', 'schmaltz', ')', 'but', 'generally', \"he's\", 'good', '.', \"there's\", 'also', 'a', 'nice', 'soundtrack', 'by', 'veteran', 'composer', 'hans', 'zimmer', '.', 'but', ',', 'generally', ',', 'as', 'good', 'as', 'it', 'gets', 'achieves', 'what', 'it', 'sets', 'out', 'to', 'do', ',', 'which', 'is', 'to', 'make', 'the', 'audience', 'feel', 'good', 'by', 'the', 'end', 'of', 'the', 'movie', '.', 'the', 'movie', 'is', 'a', 'bit', 'overlong', ',', 'but', 'nicholson', 'is', 'such', 'good', 'fun', 'that', 'the', 'running', 'time', 'passes', 'by', 'pretty', 'quickly', '.', 'overall', ',', 'as', 'good', 'as', 'it', 'gets', 'is', 'a', 'fun', 'movie', ',', 'even', 'though', 'it', 'may', 'be', 'unbelivable', ',', 'and', 'certainly', 'worth', 'seeing', '(', 'if', 'just', 'for', 'jack', 'nicholsons', 'performance', '.', ')', 'not', 'quite', 'as', 'good', 'as', 'it', 'gets', '(', 'pardon', 'the', 'bad', 'joke', ')', ',', 'but', 'still', 'good', 'fun', '.']))\n",
    "_ = test(read_document, (datasets[0]['train']['pos'][0], stopwords), set(['james', '.', 'brooks', ',', 'developers', 'simpsons', 'director', 'broadcast', 'news', ',', 'returns', 'big', 'screen', 'entertaining', ',', 'slightly', 'flawed', 'comedy', '.', 'nicholson', 'plays', 'melvin', 'udall', ',', 'horrible', 'person', 'screen', '.', 'racist', ',', 'homophobic', ',', 'good', 'word', '.', ',', 'talks', ',', 'waitress', 'carol', 'conelly', '(', '.', 'sitcom', 'star', 'hunt', ',', 'twister', ',', '1996', ')', '.', 'naturally', ',', 'udall', ',', 'conelly', 'gay', 'neighbor', 'simon', 'bishop', '(', 'kinnear', ')', 'nicholson', 'hates', ',', 'hit', 'end', '.', 'good', 'hunting', '(', '1997', ')', 'titanic', '(', '1997', ')', ',', 'outcome', 'completely', 'obvious', ',', 'good', 'enjoyable', ',', 'funny', 'warm', 'comedy', '.', 'nicholson', 'hilarious', 'melvin', ',', 'churning', 'insults', 'superb', 'relish', '.', 'nicholson', 'lines', 'melvin', 'delivers', '.', 'hunt', 'good', 'waitress', 'carol', ',', 'easily', 'rises', 'challenge', 'nicholson', '.', '(', 'thankfully', ')', 'bit', 'chemistry', '.', 'kinnear', ',', 'gay', 'neighbor', ',', 'slightly', 'underwritten', 'role', ',', 'plot', 'convience', 'character', '.', 'performance', 'good', ',', 'character', 'exist', 'melvin', 'carol', '.', 'fact', ',', 'scene', 'stealer', \"simon's\", 'dog', ',', 'funnier', 'nicholson', '.', ',', 'pets', 'cute', 'screen', '.', 'providing', 'solid', 'support', 'cuba', 'gooding', ',', 'jnr', '(', 'jerry', 'maguire', ',', '1996', ')', 'yeardly', 'smith', '(', 'voice', 'lisa', 'simpsons', 'simpsons', ')', 'gooding', 'good', 'character', 'maguire', ',', 'fun', '.', 'overacts', ',', 'annoying', '.', 'smith', 'good', ',', 'fairly', 'small', 'role', '.', 'director', 'lawrence', 'kasdan', '(', 'body', 'heat', ',', '1981', ')', 'makes', 'appearance', 'doctor', '.', 'primarily', 'nicholsons', 'film', ',', 'scene', ',', 'steals', '.', 'character', 'hateful', ',', ',', 'amazing', 'talks', ',', 'carol', '.', 'films', 'main', 'problem', '.', 'totally', 'unbelievable', 'carol', 'liking', 'melvin', '.', 'fall', 'love', 'naturally', ',', 'film', 'forces', 'fall', 'love', '.', ',', 'melvins', 'character', 'nice', ',', 'quickly', '.', 'doubt', 'character', 'melvins', 'turn', 'back', 'nice', ',', 'loving', 'person', '.', 'helluva', 'long', 'time', ',', 'longer', 'film', 'make', '.', 'brooks', 'direction', 'good', ',', ',', 'bit', 'average', ',', 'manages', 'emotion', 'audience', '.', 'handles', 'comedy', 'scenes', 'sentimental', '(', 'pile', 'schmaltz', ')', 'generally', 'good', '.', 'nice', 'soundtrack', 'veteran', 'composer', 'hans', 'zimmer', '.', ',', 'generally', ',', 'good', 'achieves', 'sets', ',', 'make', 'audience', 'feel', 'good', 'end', 'movie', '.', 'movie', 'bit', 'overlong', ',', 'nicholson', 'good', 'fun', 'running', 'time', 'passes', 'pretty', 'quickly', '.', ',', 'good', 'fun', 'movie', ',', 'unbelivable', ',', 'worth', '(', 'jack', 'nicholsons', 'performance', '.', ')', 'good', '(', 'pardon', 'bad', 'joke', ')', ',', 'good', 'fun', '.']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Učenje klasifikatora\n",
    "\n",
    "Napravi funkciju **train()** po sljedećim ulaznim i izlaznim podacima\n",
    "* ulaz:\n",
    "    * **testset** rječnik čiji ključevi su klase, a vrijednosti putanje do datoteka\n",
    "    * **stopwords** skup stop-riječi\n",
    "* izlaz:\n",
    "    * **prior** je rječnik čiji su ključevi klase, a vrijednosti prior vjerojatnosti za svaku klasu\n",
    "    * **megadoc** je rječnik čiji su ključevi klase, a vrijednosti unigram s frekvencijama riječi\n",
    "    * **vocabulary** je skup svih riječi iz svih megadokumenata\n",
    "\n",
    "\n",
    "$$P(c) = \\frac{Nc}{N}$$\n",
    "\n",
    "* $c$- klasa  \n",
    "* $Nc$ - broj dokumenata klase c  \n",
    "* $N$ - broj svih dokumenata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainset, stopwords):\n",
    "    return\n",
    "        \n",
    "testname(train)\n",
    "model = test(train, (datasets[1][\"train\"], stopwords), test_train_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Klasifikacija\n",
    "\n",
    "Napravi funkciju **classify()** po sljedećim ulaznim i izlaznim podacima\n",
    "* ulaz:\n",
    "    * **model** trenirani model kojeg vraća funkcija `train()`\n",
    "    * **filename** datoteka koja se klasificira\n",
    "    * **stopwords** stop-riječi\n",
    "* izlaz:\n",
    "    * **klasa**\n",
    "\n",
    "Vjerojatnost dokumenta $d$ za klasu $c$ se računa po Naivnom Bayesu uz dodaj-1 izglađivanje\n",
    "\n",
    "$$ P(d|c) = p(c) \\prod_{w \\in d}{p(w|c)}$$ \n",
    "\n",
    "gdje je\n",
    "\n",
    "$$ P(w|c) = \\frac{br(w,c) + 1}{br(c) + |V|}$$\n",
    "\n",
    "Na kraju, odabrana klasa se traži po\n",
    "\n",
    "$$ c_{max} = \\text{argmax}_{c \\in C} P(d | c)$$\n",
    "\n",
    "Radi preciznosti, koristiti logaritamski prostor za izračun $P(d|c)$ odnosno\n",
    "\n",
    "$$ log(P(d|c)) = log(p(c)) + \\sum_{w \\in d}{log(p(w|c))} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(model, filename, stopwords):\n",
    "    \"\"\"\n",
    "    ulaz:\n",
    "    -train_model: trenirani model kojeg vraća funkcija build_train_model()\n",
    "\n",
    "    izlaz:\n",
    "    -megadoc_model: je rječnik čiji su ključevi klase, a vrijednosti megadokumenti kao unigrami\n",
    "    nastali \"spajanjem\" svih unigrama iz treniranog modela za određenu klasu\n",
    "    \"\"\"\n",
    "    return\n",
    "        \n",
    "\n",
    "testname(classify)\n",
    "_ = test(classify, (model, datasets[1][\"test\"][\"pos\"][0], stopwords), \"pos\")\n",
    "_ = test(classify, (model, datasets[1][\"test\"][\"neg\"][0], stopwords), \"neg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Unakrsna validacija\n",
    "\n",
    "Funkcija **cross_validate()** vrši unakrsnu validaciju.\n",
    "Za svaki \"savijutak\" (engl. fold) će se trenirati klasifikator i testirati preciznost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(has_stopwords, counts):\n",
    "    \"\"\"\n",
    "    ulaz:\n",
    "    -has_stopwords: ima ili nema stop riječi\n",
    "    -counts: lista očekivanog broja točno klasificiranih dokumenata za\n",
    "             svaku unakrsnu podjelu podataka\n",
    "\n",
    "    Koraci:\n",
    "    1. Pripremi unakrsnu validaciju\n",
    "    2. Ako ima stop riječi onda ih učitaj\n",
    "    3. Za svaku unakrsnu podjelu podataka:\n",
    "       3.1. Treniraj klasifikator na podacima za trening\n",
    "       3.2. Klasificiraj na podacima za testiranje\n",
    "       3.3. Izračunaj točnost klasifikatora za unakrsnu podjelu\n",
    "    4. Izračunaj ukupnu točnost klasifikatora\n",
    "    \"\"\"\n",
    "    print('[INFO] Preparing datasets...')\n",
    "    datasets = make_datasets(DATA_PATH)\n",
    "    if has_stopwords:\n",
    "        print('[INFO] Reading stopwords...')\n",
    "        stopwords = read_stopwords(STOPWORD_FILENAME)\n",
    "    else:\n",
    "        print(\"[INFO] No stopwords...\")\n",
    "        stopwords = set()\n",
    "    print('[INFO] Training and classifying...')\n",
    "\n",
    "    total_good, total_all = 0, 0\n",
    "    for fold, dataset in enumerate(datasets):\n",
    "        print(\"[TRAIN] Fold\", fold)\n",
    "        trainset, testset = dataset['train'], dataset['test']\n",
    "        \n",
    "        model = train(trainset, stopwords)\n",
    "        print(\"[EVALUATE] Fold\", fold)\n",
    "        \n",
    "        # evaluating\n",
    "        count_good, count_all = 0, 0\n",
    "        for klass, filenames in testset.items():\n",
    "            counter = len(filenames)\n",
    "            for filename in filenames:\n",
    "                predicted_klass = classify(model, filename, stopwords)\n",
    "                count_good += 1 if predicted_klass == klass else 0\n",
    "                count_all += 1\n",
    "                counter -= 1\n",
    "                if counter % 10 == 0:\n",
    "                    i = counter // 10\n",
    "                    j = 10 - i\n",
    "                    print(klass, \"[\" + (\"=\" * j) + (\".\" * i) + \"]\", end=\"\\r\")\n",
    "            print()\n",
    "        total_good += count_good\n",
    "        total_all += count_all\n",
    "\n",
    "        success = count_good == counts[fold]\n",
    "        success_txt = ' OK ' if success else ' X  '\n",
    "\n",
    "        print(f'[{success_txt}] Fold {fold}: {count_good}/{count_all}\\t{count_good/count_all * 100:.1f}%')\n",
    "        print()\n",
    "\n",
    "    print(f'[INFO] Accuracy {total_good}/{total_all}\\t{total_good/total_all*100:.1f}%')\n",
    "\n",
    "cross_validate(False, [161,168,167,165,167,165,169,167,158,171])\n",
    "\n",
    "cross_validate(True, [162,168,168,164,167,166,168,168,153,170])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
