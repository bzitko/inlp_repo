{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "name = \"opj_v04_test.py\"\n",
    "if not os.path.exists(name):\n",
    "    response = requests.get(f\"https://raw.githubusercontent.com/bzitko/inlp_repo/main/labs/opj_v04_model_jezika/{name}\")\n",
    "    with open(name, \"wb\") as fp:\n",
    "        fp.write(response.content)\n",
    "    response.close()\n",
    "    \n",
    "name = \"alan_ford_001_grupa_tnt.txt\"\n",
    "if not os.path.exists(name):\n",
    "    response = requests.get(f\"https://raw.githubusercontent.com/bzitko/inlp_repo/main/labs/opj_v04_model_jezika/{name}\")\n",
    "    with open(name, \"wb\") as fp:\n",
    "        fp.write(response.content)\n",
    "    response.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from opj_v04_test import *\n",
    "\n",
    "def read_file(filename):\n",
    "    return open(filename, \"r\", encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model jezika\n",
    "\n",
    "## 4.1 segmentiranje rečenice\n",
    "\n",
    "Napravi funkciju **segment_sent()** po sljedećim ulaznim i izlaznim podacima\n",
    "* ulaz:\n",
    "    * **txt** tekst\n",
    "* izlaz:\n",
    "    * lista rečenica dobivenih iz teksta razbijanjem po regularnom izrazu koji traži sve **interpunkcijske znakove** i **nove redove**. Također se izbacuju sve vrste **zagrada** i **zareza** na početku i/ili kraju svake rečenice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SEGMENT_SENT\n",
      "------------------------------------------------------------\n",
      "OK\tsegment_sent('A gdje je tvoj ured?',) \n",
      "=> ['A gdje je tvoj ured']\n",
      "== ['A gdje je tvoj ured']\n",
      "\n",
      "OK\tsegment_sent('A gdje je tvoj ured? Ne znam gdje je.',) \n",
      "=> ['A gdje je tvoj ured', 'Ne znam gdje je']\n",
      "== ['A gdje je tvoj ured', 'Ne znam gdje je']\n",
      "\n",
      "OK\tsegment_sent('[Alan Ford 001 - Grupa TNT]\\nNew York, najveći grad sjedinjenih država, kip slobo...',) \n",
      "=> ['Alan Ford 001 - Grupa TNT', 'New York, najveći grad sjedinjenih država, kip slobode, neboderi, devet milijuna...', 'Čujmo malo muzike', 'Tišina me odviše podsjeća na groblje']\n",
      "== ['Alan Ford 001 - Grupa TNT', 'New York, najveći grad sjedinjenih država, kip slobode, neboderi, devet milijuna mrava što stanuju', 'Čujmo malo muzike', 'Tišina me odviše podsjeća na groblje']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def segment_sent(txt):\n",
    "    sentences = re.split(r'[\\n.\\!\\?]', txt.strip())\n",
    "    sentences = [sent.strip(' [](){},') for sent in sentences if sent.strip()]\n",
    "    return sentences\n",
    "    \n",
    "testname(segment_sent)\n",
    "test(segment_sent, (\"A gdje je tvoj ured?\", ), ['A gdje je tvoj ured'])\n",
    "test(segment_sent, (\"A gdje je tvoj ured? Ne znam gdje je.\", ), ['A gdje je tvoj ured', 'Ne znam gdje je'])\n",
    "test(segment_sent, (\"\"\"[Alan Ford 001 - Grupa TNT]\n",
    "New York, najveći grad sjedinjenih država, kip slobode, neboderi, devet milijuna mrava što stanuju...\n",
    "Čujmo malo muzike! Tišina me odviše podsjeća na groblje! \"\"\", ),\n",
    "['Alan Ford 001 - Grupa TNT',\n",
    "'New York, najveći grad sjedinjenih država, kip slobode, neboderi, devet milijuna mrava što stanuju',\n",
    "'Čujmo malo muzike',\n",
    "'Tišina me odviše podsjeća na groblje'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Segmentiranje riječi\n",
    "\n",
    "Napravi funkciju **segment_word()** po sljedećim ulaznim i izlaznim podacima\n",
    "* ulaz:\n",
    "    * **txt** tekst\n",
    "* izlaz:\n",
    "    * lista riječi u tekstu nastalih razbijanjem po regularnom izrazu koji traži sve **razmake**, **interpunkcijske znakove** i **zareze**. Također se izbacuju sve vrste **zagrada**, **navodika** i **dvotočki** na početku i/ili kraju svake riječi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SEGMENT_WORD\n",
      "------------------------------------------------------------\n",
      "OK\tsegment_word('A gdje je tvoj ured?',) \n",
      "=> ['A', 'gdje', 'je', 'tvoj', 'ured']\n",
      "== ['A', 'gdje', 'je', 'tvoj', 'ured']\n",
      "\n",
      "OK\tsegment_word('A gdje je tvoj ured? Ne znam gdje je.',) \n",
      "=> ['A', 'gdje', 'je', 'tvoj', 'ured', 'Ne', 'znam', 'gdje', 'je']\n",
      "== ['A', 'gdje', 'je', 'tvoj', 'ured', 'Ne', 'znam', 'gdje', 'je']\n",
      "\n",
      "X\tsegment_word('[Alan Ford 001 - Grupa TNT]\\nNew York, najveći grad sjedinjenih država, kip slobo...',) \n",
      "=> ['Alan', 'Ford', '001', '-', 'Grupa', 'TNT', 'New', 'York', 'najveći', 'grad', 'sjedinjenih', 'država', 'kip', 'slobode', 'neboderi', 'devet', 'milijuna', 'mrava', 'što', 'stanuju', 'Čujmo', 'malo', 'muzike', 'Tišina', 'me', 'odviše', 'podsjeća', 'na', 'groblje']\n",
      "!= ['Alan', 'Ford', '001', '-', 'Grupa', 'TNT]\\nNew', 'York', 'najveći', 'grad', 'sjedinjenih', 'država', 'kip', 'slobode', 'neboderi', 'devet', 'milijuna', 'mrava', 'što', 'stanuju', '\\nČujmo', 'malo', 'muzike', 'Tišina', 'me', 'odviše', 'podsjeća', 'na', 'groblje']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def segment_word(txt):\n",
    "    words = re.split(r'[ \\,\\.\\!\\?]', txt)\n",
    "    words = [word.strip('[](){}\"\\':') for word in words if word.strip()]\n",
    "    return words\n",
    "\n",
    "testname(segment_word)\n",
    "test(segment_word, (\"A gdje je tvoj ured?\", ), ['A', 'gdje', 'je', 'tvoj', 'ured'])\n",
    "test(segment_word, (\"A gdje je tvoj ured? Ne znam gdje je.\", ), ['A', 'gdje', 'je', 'tvoj', 'ured', 'Ne', 'znam', 'gdje', 'je'])\n",
    "test(segment_word, (\"\"\"[Alan Ford 001 - Grupa TNT]\n",
    "New York, najveći grad sjedinjenih država, kip slobode, neboderi, devet milijuna mrava što stanuju...\n",
    "Čujmo malo muzike! Tišina me odviše podsjeća na groblje! \"\"\", ),\n",
    "['Alan', 'Ford', '001', '-', 'Grupa', 'TNT', 'New', 'York', 'najveći', 'grad', 'sjedinjenih', 'država', 'kip', 'slobode', 'neboderi', 'devet', 'milijuna', 'mrava', 'što', 'stanuju', 'Čujmo', 'malo', 'muzike', 'Tišina', 'me', 'odviše', 'podsjeća', 'na', 'groblje'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Izgradnja rječnika\n",
    "\n",
    "Napravi funkciju **build_vocab()** po sljedećim ulaznim i izlaznim podacima\n",
    "* ulaz:\n",
    "    * **txt** tekst\n",
    "* izlaz:\n",
    "    * skup riječi iz teksta. Koristiti funkcije **segment_sent()** i **segment_word()** za određivanje rečenica i riječi u tekstu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BUILD_VOCAB\n",
      "------------------------------------------------------------\n",
      "OK\tbuild_vocab('A gdje je tvoj ured?',) \n",
      "=> {'ured', 'je', 'A', 'tvoj', 'gdje'}\n",
      "== {'ured', 'je', 'A', 'tvoj', 'gdje'}\n",
      "\n",
      "OK\tbuild_vocab('A gdje je tvoj ured? Ne znam gdje je.',) \n",
      "=> {'ured', 'je', 'A', 'znam', 'tvoj', 'gdje', 'Ne'}\n",
      "== {'ured', 'je', 'A', 'znam', 'tvoj', 'gdje', 'Ne'}\n",
      "\n",
      "OK\tbuild_vocab('[Alan Ford 001 - Grupa TNT]\\nNew York, najveći grad sjedinjenih država, kip slobo...',) \n",
      "=> {'-', 'slobode', 'me', 'što', 'najveći', 'kip', 'Ford', 'muzike', 'New', 'podsjeća', 'grad', '001', 'milijuna', 'stanuju', 'odviše', 'devet', 'mrava', 'York', 'neboderi', 'groblje', 'malo', 'sjedinjenih', 'Čujmo', 'Tišina', 'TNT', 'Grupa', 'država', 'na', 'Alan'}\n",
      "== {'-', 'slobode', 'me', 'što', 'najveći', 'kip', 'Ford', 'muzike', 'New', 'podsjeća', 'grad', '001', 'milijuna', 'stanuju', 'odviše', 'devet', 'mrava', 'York', 'neboderi', 'groblje', 'malo', 'sjedinjenih', 'Čujmo', 'Tišina', 'TNT', 'Grupa', 'država', 'na', 'Alan'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(txt):\n",
    "    vocab = set()\n",
    "    for sent in segment_sent(txt):\n",
    "        for word in segment_word(sent):\n",
    "            vocab.add(word)\n",
    "    return vocab\n",
    "\n",
    "testname(build_vocab)\n",
    "test(build_vocab, (\"A gdje je tvoj ured?\", ), {'A', 'gdje', 'je', 'tvoj', 'ured'})\n",
    "test(build_vocab, (\"A gdje je tvoj ured? Ne znam gdje je.\", ), {'znam', 'A', 'Ne', 'gdje', 'je', 'tvoj', 'ured'})\n",
    "test(build_vocab, (\"\"\"[Alan Ford 001 - Grupa TNT]\n",
    "New York, najveći grad sjedinjenih država, kip slobode, neboderi, devet milijuna mrava što stanuju...\n",
    "Čujmo malo muzike! Tišina me odviše podsjeća na groblje! \"\"\", ),\n",
    "{'država', 'muzike', 'Alan', 'malo', 'York', 'odviše', 'Grupa', 'TNT', 'najveći', 'groblje', 'grad', '001', 'New', 'što', 'me', 'milijuna', 'devet', 'mrava', 'sjedinjenih', '-', 'Čujmo', 'Ford', 'Tišina', 'kip', 'neboderi', 'stanuju', 'na', 'podsjeća', 'slobode'})\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Izgradnja n-grama\n",
    "\n",
    "Napravi funkciju **build_sent_ngram()** po sljedećim ulaznim i izlaznim podacima\n",
    "* ulaz:\n",
    "    * **sent** tekst rečenice\n",
    "    * **ngram_size** broj koji određuje veličinu n-grama\n",
    "* izlaz:\n",
    "    * lista n-grama zadane rečenice. n-gram je uređena n-torka (tuple) riječi. \n",
    "    \n",
    "Bitni su početak i kraj rečenice. Početak i kraj rečenice označiti sa `<sent>` i `</sent>`. \n",
    "\n",
    "**Napomena**: kod unigrama odnosno kad je ngram_size = 1 n-torka je i dalje tuple, odnosno ima oblik (riječ, )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BUILD_SENT_NGRAM\n",
      "------------------------------------------------------------\n",
      "OK\tbuild_sent_ngram('A gdje je tvoj ured?', 1) \n",
      "=> [('<sent>',), ('A',), ('gdje',), ('je',), ('tvoj',), ('ured',), ('</sent>',)]\n",
      "== [('<sent>',), ('A',), ('gdje',), ('je',), ('tvoj',), ('ured',), ('</sent>',)]\n",
      "\n",
      "OK\tbuild_sent_ngram('A gdje je tvoj ured?', 2) \n",
      "=> [('<sent>', 'A'), ('A', 'gdje'), ('gdje', 'je'), ('je', 'tvoj'), ('tvoj', 'ured'), ('ured', '</sent>')]\n",
      "== [('<sent>', 'A'), ('A', 'gdje'), ('gdje', 'je'), ('je', 'tvoj'), ('tvoj', 'ured'), ('ured', '</sent>')]\n",
      "\n",
      "OK\tbuild_sent_ngram('A gdje je tvoj ured?', 5) \n",
      "=> [('<sent>', 'A', 'gdje', 'je', 'tvoj'), ('A', 'gdje', 'je', 'tvoj', 'ured'), ('gdje', 'je', 'tvoj', 'ured', '</sent>')]\n",
      "== [('<sent>', 'A', 'gdje', 'je', 'tvoj'), ('A', 'gdje', 'je', 'tvoj', 'ured'), ('gdje', 'je', 'tvoj', 'ured', '</sent>')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_sent_ngram(sent, ngram_size):\n",
    "    ngram = []\n",
    "    sent_words = ['<sent>'] + segment_word(sent) + ['</sent>']\n",
    "    for i in range(len(sent_words) - ngram_size + int(ngram_size > 0)):\n",
    "        ngram.append(tuple(sent_words[i:i + ngram_size]))\n",
    "    return ngram\n",
    "\n",
    "testname(build_sent_ngram)\n",
    "test(build_sent_ngram, (\"A gdje je tvoj ured?\", 1), [('<sent>',), ('A',), ('gdje',), ('je',), ('tvoj',), ('ured',), ('</sent>',)])\n",
    "test(build_sent_ngram, (\"A gdje je tvoj ured?\", 2), [('<sent>', 'A'), ('A', 'gdje'), ('gdje', 'je'), ('je', 'tvoj'), ('tvoj', 'ured'), ('ured', '</sent>')])\n",
    "test(build_sent_ngram, (\"A gdje je tvoj ured?\", 5), [('<sent>', 'A', 'gdje', 'je', 'tvoj'), ('A', 'gdje', 'je', 'tvoj', 'ured'), ('gdje', 'je', 'tvoj', 'ured', '</sent>')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Prebrojavanje n-grama\n",
    "\n",
    "Napravi funkciju **count_ngrams()** po sljedećim ulaznim i izlaznim podacima\n",
    "* ulaz\n",
    "    * **txt** tekst\n",
    "    * **ngram_size** broj koji određuje veličinu n-grama    \n",
    "* izlaz\n",
    "    * rječnik čiji su ključevi ngrami (kao tuple riječi), a vrijednosti broj pojavljivanja (frekvencija) u tekstu\n",
    "    \n",
    "Napomena: bitni su početak i kraj rečenice. Početak i kraj rečenice označiti sa `<sent>` i `</sent>`. Koristiti prethodno definiranu funkciju **build_sent_ngram()**.\n",
    "\n",
    "Npr. Za tekst \"A gdje je ured? Ne znam gdje je.\" i za ngram_size = 2 dobiveni ngrami su\n",
    "\n",
    "    (\"<sent>\", \"A\"), (\"A\", \"gdje\"), (\"gdje\", \"je\"), (\"je\", \"ured\"), (\"ured\", \"</sent>\")\n",
    "    (\"<sent>\", \"Ne\"), (\"Ne\", \"znam\"), (\"znam\", \"gdje\"), (\"gdje\", \"je\"), (\"je\", \"</sent>\")\n",
    "\n",
    "a, brojač je\n",
    "\n",
    "    {(\"<sent>\", \"A\"): 1,\n",
    "     (\"A\", \"gdje\"): 1,\n",
    "     (\"gdje\", \"je\"): 2,\n",
    "     (\"je\", \"ured\"): 1,\n",
    "     (\"ured\", \"</sent>\"): 1,\n",
    "     (\"<sent>\", \"Ne\"): 1,\n",
    "     (\"Ne\", \"znam\"): 1,\n",
    "     (\"znam\", \"gdje\"): 1,\n",
    "     (\"je\", \"</sent>\": 1)\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COUNT_NGRAMS\n",
      "------------------------------------------------------------\n",
      "OK\tcount_ngrams('A gdje je tvoj ured? Ne znam gdje je.', 1) \n",
      "=> {('<sent>',): 2, ('A',): 1, ('gdje',): 2}\n",
      "== {('<sent>',): 2, ('A',): 1, ('gdje',): 2, ('je',): 2, ('tvoj',): 1, ('ured',): 1, ('</sent>',): 2, ('Ne',): 1, ('znam',): 1}\n",
      "\n",
      "OK\tcount_ngrams('A gdje je tvoj ured? Ne znam gdje je.', 2) \n",
      "=> {('<sent>', 'A'): 1, ('A', 'gdje'): 1, ('gdje', 'je'): 2}\n",
      "== {('<sent>', 'A'): 1, ('A', 'gdje'): 1, ('gdje', 'je'): 2, ('je', 'tvoj'): 1, ('tvoj', 'ured'): 1, ('ured', '</sent>'): 1, ('<sent>', 'Ne'): 1, ('Ne', 'znam'): 1, ('znam', 'gdje'): 1, ('je', '</sent>'): 1}\n",
      "\n",
      "OK\tcount_ngrams('[Alan Ford 001 - Grupa TNT]\\n\\nNew York, najveći grad sjedinjenih država, kip slob...', 1) \n",
      "=> {1: 1180, 2: 183, 3: 73, 4: 44, 5: 20, 6: 8, 7: 15, 8: 13, 9: 4, 10: 3, 11: 2, 12: 3, 13: 1, 14: 3, 15: 4, 16: 2, 17: 1, 18: 1, 19: 4, 20: 1, 22: 1, 27: 1, 31: 1, 34: 1, 35: 1, 40: 1, 46: 1, 47: 1, 55: 1, 97: 1, 101: 1, 109: 1, 688: 2}\n",
      "== {1: 1180, 2: 183, 3: 73, 4: 44, 5: 20, 6: 8, 7: 15, 8: 13, 9: 4, 10: 3, 11: 2, 12: 3, 13: 1, 14: 3, 15: 4, 16: 2, 17: 1, 18: 1, 19: 4, 20: 1, 22: 1, 27: 1, 31: 1, 34: 1, 35: 1, 40: 1, 46: 1, 47: 1, 55: 1, 97: 1, 101: 1, 109: 1, 688: 2}\n",
      "\n",
      "OK\tcount_ngrams('[Alan Ford 001 - Grupa TNT]\\n\\nNew York, najveći grad sjedinjenih država, kip slob...', 2) \n",
      "=> {1: 2910, 2: 220, 3: 61, 4: 30, 5: 10, 6: 6, 7: 9, 8: 6, 9: 3, 10: 4, 14: 2, 15: 3, 20: 1, 22: 1}\n",
      "== {1: 2910, 2: 220, 3: 61, 4: 30, 5: 10, 6: 6, 7: 9, 8: 6, 9: 3, 10: 4, 14: 2, 15: 3, 20: 1, 22: 1}\n",
      "\n",
      "OK\tcount_ngrams('[Alan Ford 001 - Grupa TNT]\\n\\nNew York, najveći grad sjedinjenih država, kip slob...', 3) \n",
      "=> {1: 3055, 2: 78, 3: 19, 4: 7, 6: 3, 7: 2, 8: 2}\n",
      "== {1: 3055, 2: 78, 3: 19, 4: 7, 6: 3, 7: 2, 8: 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_ngrams(txt, ngram_size):\n",
    "    counter = {}\n",
    "    for sent in segment_sent(txt):\n",
    "        for ngram in build_sent_ngram(sent, ngram_size):\n",
    "            counter[ngram] = counter.get(ngram, 0) + 1\n",
    "    return counter\n",
    "\n",
    "FILENAME = 'alan_ford_001_grupa_tnt.txt'\n",
    "testname(count_ngrams)\n",
    "test(count_ngrams, (\"A gdje je tvoj ured? Ne znam gdje je.\", 1), {('<sent>',): 2, ('A',): 1, ('gdje',): 2, ('je',): 2, ('tvoj',): 1, ('ured',): 1, ('</sent>',): 2, ('Ne',): 1, ('znam',): 1})\n",
    "test(count_ngrams, (\"A gdje je tvoj ured? Ne znam gdje je.\", 2), {('<sent>', 'A'): 1, ('A', 'gdje'): 1, ('gdje', 'je'): 2, ('je', 'tvoj'): 1, ('tvoj', 'ured'): 1, ('ured', '</sent>'): 1, ('<sent>', 'Ne'): 1, ('Ne', 'znam'): 1, ('znam', 'gdje'): 1, ('je', '</sent>'): 1})\n",
    "counter1 = test_model(count_ngrams, (read_file(FILENAME), 1), {1: 1180, 2: 183, 3: 73, 4: 44, 5: 20, 6: 8, 7: 15, 8: 13, 9: 4, 10: 3, 11: 2, 12: 3, 13: 1, 14: 3, 15: 4, 16: 2, 17: 1, 18: 1, 19: 4, 20: 1, 22: 1, 27: 1, 31: 1, 34: 1, 35: 1, 40: 1, 46: 1, 47: 1, 55: 1, 97: 1, 101: 1, 109: 1, 688: 2})\n",
    "counter2 = test_model(count_ngrams, (read_file(FILENAME), 2), {1: 2910, 2: 220, 3: 61, 4: 30, 5: 10, 6: 6, 7: 9, 8: 6, 9: 3, 10: 4, 14: 2, 15: 3, 20: 1, 22: 1})\n",
    "counter3 = test_model(count_ngrams, (read_file(FILENAME), 3), {1: 3055, 2: 78, 3: 19, 4: 7, 6: 3, 7: 2, 8: 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Izgradnja modela jezika\n",
    "\n",
    "Napravi funkciju **build_lang_model()** po sljedećim ulaznim i izlaznim podacima\n",
    "* ulaz\n",
    "    * **txt** tekst\n",
    "    * **ngram_size** broj koji određuje veličinu n-grama\n",
    "* izlaz\n",
    "    * rječnik čiji su ključevi ngrami (kao tuple riječi), a vrijednosti broj pojavljivanja (frekvencija) u tekstu\n",
    "    \n",
    "    \n",
    "Napomena: za bigrame vjerojatnost pojedinog bigrama (A, B) je jednaka broju pojavljivanja bigrama (A, B) podijeljenog s brojem pojavljivanja unigrama (A, )\n",
    "\n",
    "$$P(A, B) = \\frac{broj((A, B))}{broj(A)}$$    \n",
    "    \n",
    "Napomena: za trigrame vjerojatnost pojedinih trigrama (A, B, C) je jednaka broju pojavljivanja trigrama (A, B, C) podijeljenog s brojem pojavlivanja bigrama (A, B)\n",
    "\n",
    "$$P(A, B, C) = \\frac{broj((A, B, C))}{broj(A, B)}$$    \n",
    "\n",
    "Npr. Za tekst \"A gdje je ured? Ne znam gdje je.\" i za ngram_size = 2 dobiveni bigrami su\n",
    "\n",
    "    (\"<sent>\", \"A\"), (\"A\", \"gdje\"), (\"gdje\", \"je\"), (\"je\", \"ured\"), (\"ured\", \"</sent>\")\n",
    "    (\"<sent>\", \"Ne\"), (\"Ne\", \"znam\"), (\"znam\", \"gdje\"), (\"gdje\", \"je\"), (\"je\", \"</sent>\")\n",
    "\n",
    "brojač bigrama je \n",
    "\n",
    "    {(\"<sent>\", \"A\"): 1,\n",
    "     (\"A\", \"gdje\"): 1,\n",
    "     (\"gdje\", \"je\"): 2,\n",
    "     (\"je\", \"ured\"): 1,\n",
    "     (\"ured\", \"</sent>\"): 1,\n",
    "     (\"<sent>\", \"Ne\"): 1,\n",
    "     (\"Ne\", \"znam\"): 1,\n",
    "     (\"znam\", \"gdje\"): 1,\n",
    "     (\"je\", \"</sent>\": 1)\n",
    "     }\n",
    "    \n",
    "brojač unigrama je\n",
    "\n",
    "    {('<sent>',): 2, \n",
    "     ('A',): 1, \n",
    "     ('gdje',): 2, \n",
    "     ('je',): 2, \n",
    "     ('tvoj',): 1, \n",
    "     ('ured',): 1, \n",
    "     ('</sent>',): 2, \n",
    "     ('Ne',): 1, \n",
    "     ('znam',): 1}\n",
    "     \n",
    "model jezika je\n",
    "\n",
    "    {('<sent>', 'A'): 0.5, \n",
    "     ('A', 'gdje'): 1.0, \n",
    "     ('gdje', 'je'): 1.0, \n",
    "     ('je', 'tvoj'): 0.5, \n",
    "     ('tvoj', 'ured'): 1.0,\n",
    "     ('ured', '</sent>'): 1.0, \n",
    "     ('<sent>', 'Ne'): 0.5, \n",
    "     ('Ne', 'znam'): 1.0, \n",
    "     ('znam', 'gdje'): 1.0, \n",
    "     ('je', '</sent>'): 0.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\tbuild_lang_model('A gdje je tvoj ured? Ne znam gdje je.', 1) \n",
      "=> {('<sent>',): 0.15384615384615385, ('A',): 0.07692307692307693, ('gdje',): 0.15384615384615385}\n",
      "== {('<sent>',): 0.15384615384615385, ('A',): 0.07692307692307693, ('gdje',): 0.15384615384615385, ('je',): 0.15384615384615385, ('tvoj',): 0.07692307692307693, ('ured',): 0.07692307692307693, ('</sent>',): 0.15384615384615385, ('Ne',): 0.07692307692307693, ('znam',): 0.07692307692307693}\n",
      "\n",
      "OK\tbuild_lang_model('A gdje je tvoj ured? Ne znam gdje je.', 2) \n",
      "=> {('<sent>', 'A'): 0.5, ('A', 'gdje'): 1.0, ('gdje', 'je'): 1.0}\n",
      "== {('<sent>', 'A'): 0.5, ('A', 'gdje'): 1.0, ('gdje', 'je'): 1.0, ('je', 'tvoj'): 0.5, ('tvoj', 'ured'): 1.0, ('ured', '</sent>'): 1.0, ('<sent>', 'Ne'): 0.5, ('Ne', 'znam'): 1.0, ('znam', 'gdje'): 1.0, ('je', '</sent>'): 0.5}\n",
      "\n",
      "OK\tbuild_lang_model('A gdje je tvoj ured? Ne znam gdje je.', 3) \n",
      "=> {('<sent>', 'A', 'gdje'): 1.0, ('A', 'gdje', 'je'): 1.0, ('gdje', 'je', 'tvoj'): 0.5}\n",
      "== {('<sent>', 'A', 'gdje'): 1.0, ('A', 'gdje', 'je'): 1.0, ('gdje', 'je', 'tvoj'): 0.5, ('je', 'tvoj', 'ured'): 1.0, ('tvoj', 'ured', '</sent>'): 1.0, ('<sent>', 'Ne', 'znam'): 1.0, ('Ne', 'znam', 'gdje'): 1.0, ('znam', 'gdje', 'je'): 1.0, ('gdje', 'je', '</sent>'): 0.5}\n",
      "\n",
      "OK\tbuild_lang_model('[Alan Ford 001 - Grupa TNT]\\n\\nNew York, najveći grad sjedinjenih država, kip slob...', 1) \n",
      "=> {'2.12e-04': 1180, '4.24e-04': 183, '6.36e-04': 73, '8.47e-04': 44, '1.06e-03': 20, '1.27e-03': 8, '1.48e-03': 15, '1.69e-03': 13, '1.91e-03': 4, '2.12e-03': 3, '2.33e-03': 2, '2.54e-03': 3, '2.75e-03': 1, '2.97e-03': 3, '3.18e-03': 4, '3.39e-03': 2, '3.60e-03': 1, '3.81e-03': 1, '4.03e-03': 4, '4.24e-03': 1, '4.66e-03': 1, '5.72e-03': 1, '6.57e-03': 1, '7.20e-03': 1, '7.42e-03': 1, '8.47e-03': 1, '9.75e-03': 1, '9.96e-03': 1, '1.17e-02': 1, '2.06e-02': 1, '2.14e-02': 1, '2.31e-02': 1, '1.46e-01': 2}\n",
      "== {'2.12e-04': 1180, '4.24e-04': 183, '6.36e-04': 73, '8.47e-04': 44, '1.06e-03': 20, '1.27e-03': 8, '1.48e-03': 15, '1.69e-03': 13, '1.91e-03': 4, '2.12e-03': 3, '2.33e-03': 2, '2.54e-03': 3, '2.75e-03': 1, '2.97e-03': 3, '3.18e-03': 4, '3.39e-03': 2, '3.60e-03': 1, '3.81e-03': 1, '4.03e-03': 4, '4.24e-03': 1, '4.66e-03': 1, '5.72e-03': 1, '6.57e-03': 1, '7.20e-03': 1, '7.42e-03': 1, '8.47e-03': 1, '9.75e-03': 1, '9.96e-03': 1, '1.17e-02': 1, '2.06e-02': 1, '2.14e-02': 1, '2.31e-02': 1, '1.46e-01': 2}\n",
      "\n",
      "OK\tbuild_lang_model('[Alan Ford 001 - Grupa TNT]\\n\\nNew York, najveći grad sjedinjenih država, kip slob...', 2) \n",
      "=> {'1.45e-03': 269, '2.91e-03': 47, '4.36e-03': 20, '5.81e-03': 13, '7.27e-03': 6, '8.72e-03': 4, '9.17e-03': 80, '9.90e-03': 49, '1.02e-02': 4, '1.03e-02': 48, '1.16e-02': 4, '1.31e-02': 1, '1.45e-02': 1, '1.82e-02': 29, '1.83e-02': 6, '1.98e-02': 7, '2.03e-02': 2, '2.06e-02': 6, '2.13e-02': 33, '2.17e-02': 35, '2.18e-02': 2, '2.50e-02': 36, '2.86e-02': 26, '2.94e-02': 23, '2.97e-02': 1, '3.09e-02': 2, '3.20e-02': 1, '3.23e-02': 26, '3.64e-02': 6, '3.67e-02': 2, '3.70e-02': 23, '3.96e-02': 2, '4.12e-02': 1, '4.26e-02': 7, '4.35e-02': 4, '4.55e-02': 14, '5.00e-02': 5, '5.26e-02': 44, '5.45e-02': 3, '5.56e-02': 16, '5.71e-02': 2, '5.88e-02': 11, '6.25e-02': 17, '6.45e-02': 1, '6.52e-02': 1, '6.67e-02': 39, '7.14e-02': 31, '7.22e-02': 1, '7.41e-02': 2, '7.69e-02': 13, '7.92e-02': 1, '8.26e-02': 1, '8.33e-02': 28, '8.91e-02': 1, '9.09e-02': 17, '9.68e-02': 1, '9.90e-02': 1, '1.00e-01': 12, '1.05e-01': 8, '1.11e-01': 33, '1.18e-01': 1, '1.25e-01': 67, '1.33e-01': 2, '1.43e-01': 81, '1.67e-01': 34, '1.76e-01': 2, '2.00e-01': 71, '2.06e-01': 1, '2.11e-01': 1, '2.22e-01': 2, '2.50e-01': 131, '2.63e-01': 1, '2.67e-01': 1, '2.73e-01': 2, '2.86e-01': 5, '3.33e-01': 142, '3.50e-01': 1, '3.64e-01': 1, '3.68e-01': 1, '3.75e-01': 2, '4.00e-01': 9, '4.29e-01': 3, '5.00e-01': 295, '5.71e-01': 2, '6.00e-01': 3, '6.25e-01': 1, '6.67e-01': 23, '7.50e-01': 8, '8.00e-01': 3, '9.38e-01': 1, '1.00e+00': 1239}\n",
      "== {'1.45e-03': 269, '2.91e-03': 47, '4.36e-03': 20, '5.81e-03': 13, '7.27e-03': 6, '8.72e-03': 4, '9.17e-03': 80, '9.90e-03': 49, '1.02e-02': 4, '1.03e-02': 48, '1.16e-02': 4, '1.31e-02': 1, '1.45e-02': 1, '1.82e-02': 29, '1.83e-02': 6, '1.98e-02': 7, '2.03e-02': 2, '2.06e-02': 6, '2.13e-02': 33, '2.17e-02': 35, '2.18e-02': 2, '2.50e-02': 36, '2.86e-02': 26, '2.94e-02': 23, '2.97e-02': 1, '3.09e-02': 2, '3.20e-02': 1, '3.23e-02': 26, '3.64e-02': 6, '3.67e-02': 2, '3.70e-02': 23, '3.96e-02': 2, '4.12e-02': 1, '4.26e-02': 7, '4.35e-02': 4, '4.55e-02': 14, '5.00e-02': 5, '5.26e-02': 44, '5.45e-02': 3, '5.56e-02': 16, '5.71e-02': 2, '5.88e-02': 11, '6.25e-02': 17, '6.45e-02': 1, '6.52e-02': 1, '6.67e-02': 39, '7.14e-02': 31, '7.22e-02': 1, '7.41e-02': 2, '7.69e-02': 13, '7.92e-02': 1, '8.26e-02': 1, '8.33e-02': 28, '8.91e-02': 1, '9.09e-02': 17, '9.68e-02': 1, '9.90e-02': 1, '1.00e-01': 12, '1.05e-01': 8, '1.11e-01': 33, '1.18e-01': 1, '1.25e-01': 67, '1.33e-01': 2, '1.43e-01': 81, '1.67e-01': 34, '1.76e-01': 2, '2.00e-01': 71, '2.06e-01': 1, '2.11e-01': 1, '2.22e-01': 2, '2.50e-01': 131, '2.63e-01': 1, '2.67e-01': 1, '2.73e-01': 2, '2.86e-01': 5, '3.33e-01': 142, '3.50e-01': 1, '3.64e-01': 1, '3.68e-01': 1, '3.75e-01': 2, '4.00e-01': 9, '4.29e-01': 3, '5.00e-01': 295, '5.71e-01': 2, '6.00e-01': 3, '6.25e-01': 1, '6.67e-01': 23, '7.50e-01': 8, '8.00e-01': 3, '9.38e-01': 1, '1.00e+00': 1239}\n",
      "\n",
      "OK\tbuild_lang_model('[Alan Ford 001 - Grupa TNT]\\n\\nNew York, najveći grad sjedinjenih država, kip slob...', 3) \n",
      "=> {'4.55e-02': 14, '5.00e-02': 10, '6.67e-02': 25, '7.14e-02': 19, '9.09e-02': 1, '1.00e-01': 14, '1.11e-01': 19, '1.25e-01': 29, '1.33e-01': 3, '1.43e-01': 32, '1.67e-01': 18, '2.00e-01': 31, '2.22e-01': 4, '2.50e-01': 71, '2.67e-01': 1, '2.73e-01': 1, '2.86e-01': 2, '3.00e-01': 1, '3.33e-01': 75, '3.75e-01': 1, '4.00e-01': 3, '4.29e-01': 1, '4.67e-01': 1, '5.00e-01': 254, '5.71e-01': 1, '6.00e-01': 2, '6.67e-01': 9, '7.50e-01': 5, '8.00e-01': 3, '1.00e+00': 2516}\n",
      "== {'4.55e-02': 14, '5.00e-02': 10, '6.67e-02': 25, '7.14e-02': 19, '9.09e-02': 1, '1.00e-01': 14, '1.11e-01': 19, '1.25e-01': 29, '1.33e-01': 3, '1.43e-01': 32, '1.67e-01': 18, '2.00e-01': 31, '2.22e-01': 4, '2.50e-01': 71, '2.67e-01': 1, '2.73e-01': 1, '2.86e-01': 2, '3.00e-01': 1, '3.33e-01': 75, '3.75e-01': 1, '4.00e-01': 3, '4.29e-01': 1, '4.67e-01': 1, '5.00e-01': 254, '5.71e-01': 1, '6.00e-01': 2, '6.67e-01': 9, '7.50e-01': 5, '8.00e-01': 3, '1.00e+00': 2516}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_lang_model(txt, ngram_size):\n",
    "    counter_hi = count_ngrams(txt, ngram_size=ngram_size)\n",
    "    counter_lo = count_ngrams(txt, ngram_size=ngram_size - 1)\n",
    "    \n",
    "    model = {}\n",
    "    for ngram in counter_hi:\n",
    "        model[ngram] = counter_hi[ngram] / counter_lo[ngram[:-1]]\n",
    "    return model\n",
    "\n",
    "test(build_lang_model, (\"A gdje je tvoj ured? Ne znam gdje je.\", 1), {('<sent>',): 0.15384615384615385, ('A',): 0.07692307692307693, ('gdje',): 0.15384615384615385, ('je',): 0.15384615384615385, ('tvoj',): 0.07692307692307693, ('ured',): 0.07692307692307693, ('</sent>',): 0.15384615384615385, ('Ne',): 0.07692307692307693, ('znam',): 0.07692307692307693})\n",
    "test(build_lang_model, (\"A gdje je tvoj ured? Ne znam gdje je.\", 2), {('<sent>', 'A'): 0.5, ('A', 'gdje'): 1.0, ('gdje', 'je'): 1.0, ('je', 'tvoj'): 0.5, ('tvoj', 'ured'): 1.0, ('ured', '</sent>'): 1.0, ('<sent>', 'Ne'): 0.5, ('Ne', 'znam'): 1.0, ('znam', 'gdje'): 1.0, ('je', '</sent>'): 0.5})\n",
    "test(build_lang_model, (\"A gdje je tvoj ured? Ne znam gdje je.\", 3), {('<sent>', 'A', 'gdje'): 1.0, ('A', 'gdje', 'je'): 1.0, ('gdje', 'je', 'tvoj'): 0.5, ('je', 'tvoj', 'ured'): 1.0, ('tvoj', 'ured', '</sent>'): 1.0, ('<sent>', 'Ne', 'znam'): 1.0, ('Ne', 'znam', 'gdje'): 1.0, ('znam', 'gdje', 'je'): 1.0, ('gdje', 'je', '</sent>'): 0.5})\n",
    "\n",
    "model1 = test_model(build_lang_model, (read_file(FILENAME), 1), {'2.12e-04': 1180, '4.24e-04': 183, '6.36e-04': 73, '8.47e-04': 44, '1.06e-03': 20, '1.27e-03': 8, '1.48e-03': 15, '1.69e-03': 13, '1.91e-03': 4, '2.12e-03': 3, '2.33e-03': 2, '2.54e-03': 3, '2.75e-03': 1, '2.97e-03': 3, '3.18e-03': 4, '3.39e-03': 2, '3.60e-03': 1, '3.81e-03': 1, '4.03e-03': 4, '4.24e-03': 1, '4.66e-03': 1, '5.72e-03': 1, '6.57e-03': 1, '7.20e-03': 1, '7.42e-03': 1, '8.47e-03': 1, '9.75e-03': 1, '9.96e-03': 1, '1.17e-02': 1, '2.06e-02': 1, '2.14e-02': 1, '2.31e-02': 1, '1.46e-01': 2})\n",
    "model2 = test_model(build_lang_model, (read_file(FILENAME), 2), {'1.45e-03': 269, '2.91e-03': 47, '4.36e-03': 20, '5.81e-03': 13, '7.27e-03': 6, '8.72e-03': 4, '9.17e-03': 80, '9.90e-03': 49, '1.02e-02': 4, '1.03e-02': 48, '1.16e-02': 4, '1.31e-02': 1, '1.45e-02': 1, '1.82e-02': 29, '1.83e-02': 6, '1.98e-02': 7, '2.03e-02': 2, '2.06e-02': 6, '2.13e-02': 33, '2.17e-02': 35, '2.18e-02': 2, '2.50e-02': 36, '2.86e-02': 26, '2.94e-02': 23, '2.97e-02': 1, '3.09e-02': 2, '3.20e-02': 1, '3.23e-02': 26, '3.64e-02': 6, '3.67e-02': 2, '3.70e-02': 23, '3.96e-02': 2, '4.12e-02': 1, '4.26e-02': 7, '4.35e-02': 4, '4.55e-02': 14, '5.00e-02': 5, '5.26e-02': 44, '5.45e-02': 3, '5.56e-02': 16, '5.71e-02': 2, '5.88e-02': 11, '6.25e-02': 17, '6.45e-02': 1, '6.52e-02': 1, '6.67e-02': 39, '7.14e-02': 31, '7.22e-02': 1, '7.41e-02': 2, '7.69e-02': 13, '7.92e-02': 1, '8.26e-02': 1, '8.33e-02': 28, '8.91e-02': 1, '9.09e-02': 17, '9.68e-02': 1, '9.90e-02': 1, '1.00e-01': 12, '1.05e-01': 8, '1.11e-01': 33, '1.18e-01': 1, '1.25e-01': 67, '1.33e-01': 2, '1.43e-01': 81, '1.67e-01': 34, '1.76e-01': 2, '2.00e-01': 71, '2.06e-01': 1, '2.11e-01': 1, '2.22e-01': 2, '2.50e-01': 131, '2.63e-01': 1, '2.67e-01': 1, '2.73e-01': 2, '2.86e-01': 5, '3.33e-01': 142, '3.50e-01': 1, '3.64e-01': 1, '3.68e-01': 1, '3.75e-01': 2, '4.00e-01': 9, '4.29e-01': 3, '5.00e-01': 295, '5.71e-01': 2, '6.00e-01': 3, '6.25e-01': 1, '6.67e-01': 23, '7.50e-01': 8, '8.00e-01': 3, '9.38e-01': 1, '1.00e+00': 1239})\n",
    "model3 = test_model(build_lang_model, (read_file(FILENAME), 3), {'4.55e-02': 14, '5.00e-02': 10, '6.67e-02': 25, '7.14e-02': 19, '9.09e-02': 1, '1.00e-01': 14, '1.11e-01': 19, '1.25e-01': 29, '1.33e-01': 3, '1.43e-01': 32, '1.67e-01': 18, '2.00e-01': 31, '2.22e-01': 4, '2.50e-01': 71, '2.67e-01': 1, '2.73e-01': 1, '2.86e-01': 2, '3.00e-01': 1, '3.33e-01': 75, '3.75e-01': 1, '4.00e-01': 3, '4.29e-01': 1, '4.67e-01': 1, '5.00e-01': 254, '5.71e-01': 1, '6.00e-01': 2, '6.67e-01': 9, '7.50e-01': 5, '8.00e-01': 3, '1.00e+00': 2516})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Vjerojarnost rečenice\n",
    "\n",
    "Napravi funkciju **sent_prob()** po sljedećim ulaznim i izlaznim podacima\n",
    "* ulaz\n",
    "    * **txt** tekst rečenice\n",
    "    * **model** model jezika kao rječnik čiji ključevi su ngrami, a vrijednosti njihove vjerojatnosti\n",
    "* izlaz\n",
    "    * vjeroratnost rečenice po modelu jezika \n",
    "    \n",
    "Napomena: koristiti **build_sent_ngram()** za napraviti ngram rečenice. Za ngram_size je dovoljno uzeti bilo koji ngram iz modela i pogledati njegovu veličinu.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\tsent_prob('Hm... uvijek kad zakočim ispadne kotač i ne čeka.', {('<sent>',): 0.14576271186440679, ('Alan',): 0.003389830508474576, ('Ford',): 0.004025423728813559}) \n",
      "=> 8.755353678606873e-29\n",
      "== 8.755353678606873e-29\n",
      "\n",
      "OK\tsent_prob('U ovih nekoliko posljednjih sati, život se budio prolaznici su zaista dosadni!', {('<sent>', 'Alan'): 0.007267441860465116, ('Alan', 'Ford'): 0.9375, ('Ford', '001'): 0.05263157894736842}) \n",
      "=> 1.9510958603052824e-09\n",
      "== 1.9510958603052824e-09\n",
      "\n",
      "OK\tsent_prob('A gdje je tvoj ured?', {('<sent>', 'Alan', 'Ford'): 0.8, ('Alan', 'Ford', '001'): 0.06666666666666667, ('Ford', '001', '-'): 1.0}) \n",
      "=> 0.022727272727272728\n",
      "== 0.022727272727272728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sent_prob(sent, model):\n",
    "    prob = 1\n",
    "    ngram_size = len(next(iter(model)))\n",
    "    for ngram in build_sent_ngram(sent, ngram_size=ngram_size):\n",
    "        prob *= model[ngram]\n",
    "    return prob\n",
    "        \n",
    "\n",
    "    \n",
    "test(sent_prob, (\"Hm... uvijek kad zakočim ispadne kotač i ne čeka.\", model1), 8.755353678606873e-29)\n",
    "test(sent_prob, (\"U ovih nekoliko posljednjih sati, život se budio prolaznici su zaista dosadni!\", model2), 1.9510958603052824e-09)\n",
    "test(sent_prob, (\"A gdje je tvoj ured?\", model3), 0.022727272727272728)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7. Izgradnja modela jezika po Laplace-u (dodaj-1 izglađivanje)\n",
    "\n",
    "Napraviti klasu **LangModelLaplace** koja će imati sljedeće specijalne metode:\n",
    "\n",
    "* `__init__(self, txt, ngram_size)` metoda koja će za dani **txt** i **ngram_size** stvoriti atribute:\n",
    "    * `self.counter_hi` - brojač ngrama u tekstu `txt` za `ngram_size`. Koristiti **build_counter()**.\n",
    "    * `self.counter_lo` - brojač ngrama u tekstu `txt` za `ngram_size - 1`. Koristiti **build_counter()**.\n",
    "    * `v` - veličina rječnika za `txt` uvečana za 2 jer dodajemo `<sent>` i `</sent>`.  Koristiti **build_vocab()**\n",
    "* `__getitem__(self, ngram)` metoda koja će za dani **ngram** vratiti vjerojatnost ngrama po Laplace-u. `self.counter_hi`sadrži brojač ngrama za brojnik, a `self.counter_lo`sadrži brojač ngrama za nazivnik. Ova specijalna metoda omogućava da se na instanci klase pristupa nekoj vrijednosti kao kod rječnika. Odnosno, ako je \n",
    "`model_laplace` instanca klase `LangModelLaplace`, onda se vrijednosti ngrama `ngram` pristupa s `model_laplace[ngram]`.\n",
    "\n",
    "Napomena: za bigrame, vjerojatnost pojedinog bigrama $(w_{i-1}, w_i)$ je jednaka \n",
    "\n",
    "$$P(w_{i-1}, w_i) = \\frac{broj((w_{i-1}, w_i)) + 1}{broj(w_{i-1}) + |V|}$$\n",
    "\n",
    "gdje je $|V|$ veličina rječnika.\n",
    "    \n",
    "Napomena: za trigrame, vjerojatnost pojedinih trigrama $(w_{i-2}, w_{i-1}, w_i)$ je jednaka \n",
    "\n",
    "$$P(w_{i-2}, w_{i-1}, w_i) = \\frac{broj((w_{i-2}, w_{i-1}, w_i) + 1}{broj(w_{i-2}, w_{i-1}) + |V|}$$\n",
    "\n",
    "gdje je $|V|$ veličina rječnika.\n",
    "\n",
    "Napravljena funkcija **build_lang_model_laplace()** jednostavno vraća instancu **LangModelLaplace** klase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BUILD_LANG_MODEL_LAPLACE\n",
      "------------------------------------------------------------\n",
      "OK\tbuild_lang_model('A gdje je tvoj ured? Ne znam gdje je.', 1) \n",
      "=> {('<sent>',): 0.15384615384615385, ('A',): 0.07692307692307693, ('gdje',): 0.15384615384615385}\n",
      "== {('<sent>',): 0.15384615384615385, ('A',): 0.07692307692307693, ('gdje',): 0.15384615384615385, ('je',): 0.15384615384615385, ('tvoj',): 0.07692307692307693, ('ured',): 0.07692307692307693, ('</sent>',): 0.15384615384615385, ('Ne',): 0.07692307692307693, ('znam',): 0.07692307692307693}\n",
      "\n",
      "OK\tbuild_lang_model_laplace('A gdje je tvoj ured? Ne znam gdje je.', 1) \n",
      "=> {('<sent>',): 0.13636363636363635, ('A',): 0.09090909090909091, ('gdje',): 0.13636363636363635}\n",
      "== {('<sent>',): 0.13636363636363635, ('A',): 0.09090909090909091, ('gdje',): 0.13636363636363635, ('je',): 0.13636363636363635, ('tvoj',): 0.09090909090909091, ('ured',): 0.09090909090909091, ('</sent>',): 0.13636363636363635, ('Ne',): 0.09090909090909091, ('znam',): 0.09090909090909091}\n",
      "\n",
      "OK\tbuild_lang_model('A gdje je ured tvoj? Ne znam gdje je.', 2) \n",
      "=> {('<sent>', 'A'): 0.5, ('A', 'gdje'): 1.0, ('gdje', 'je'): 1.0}\n",
      "== {('<sent>', 'A'): 0.5, ('A', 'gdje'): 1.0, ('gdje', 'je'): 1.0, ('je', 'ured'): 0.5, ('ured', 'tvoj'): 1.0, ('tvoj', '</sent>'): 1.0, ('<sent>', 'Ne'): 0.5, ('Ne', 'znam'): 1.0, ('znam', 'gdje'): 1.0, ('je', '</sent>'): 0.5}\n",
      "\n",
      "OK\tbuild_lang_model_laplace('A gdje je ured tvoj? Ne znam gdje je.', 2) \n",
      "=> {('<sent>', 'A'): 0.18181818181818182, ('A', 'gdje'): 0.2, ('gdje', 'je'): 0.2727272727272727}\n",
      "== {('<sent>', 'A'): 0.18181818181818182, ('A', 'gdje'): 0.2, ('gdje', 'je'): 0.2727272727272727, ('je', 'ured'): 0.18181818181818182, ('ured', 'tvoj'): 0.2, ('tvoj', '</sent>'): 0.2, ('<sent>', 'Ne'): 0.18181818181818182, ('Ne', 'znam'): 0.2, ('znam', 'gdje'): 0.2, ('je', '</sent>'): 0.18181818181818182}\n",
      "\n",
      "OK\tbuild_lang_model_laplace('[Alan Ford 001 - Grupa TNT]\\n\\nNew York, najveći grad sjedinjenih država, kip slob...', 1) \n",
      "=> {'3.18e-04': 1180, '4.76e-04': 183, '6.35e-04': 73, '7.94e-04': 44, '9.53e-04': 20, '1.11e-03': 8, '1.27e-03': 15, '1.43e-03': 13, '1.59e-03': 4, '1.75e-03': 3, '1.91e-03': 2, '2.06e-03': 3, '2.22e-03': 1, '2.38e-03': 3, '2.54e-03': 4, '2.70e-03': 2, '2.86e-03': 1, '3.02e-03': 1, '3.18e-03': 4, '3.33e-03': 1, '3.65e-03': 1, '4.45e-03': 1, '5.08e-03': 1, '5.56e-03': 1, '5.72e-03': 1, '6.51e-03': 1, '7.46e-03': 1, '7.62e-03': 1, '8.89e-03': 1, '1.56e-02': 1, '1.62e-02': 1, '1.75e-02': 1, '1.09e-01': 2}\n",
      "== {'3.18e-04': 1180, '4.76e-04': 183, '6.35e-04': 73, '7.94e-04': 44, '9.53e-04': 20, '1.11e-03': 8, '1.27e-03': 15, '1.43e-03': 13, '1.59e-03': 4, '1.75e-03': 3, '1.91e-03': 2, '2.06e-03': 3, '2.22e-03': 1, '2.38e-03': 3, '2.54e-03': 4, '2.70e-03': 2, '2.86e-03': 1, '3.02e-03': 1, '3.18e-03': 4, '3.33e-03': 1, '3.65e-03': 1, '4.45e-03': 1, '5.08e-03': 1, '5.56e-03': 1, '5.72e-03': 1, '6.51e-03': 1, '7.46e-03': 1, '7.62e-03': 1, '8.89e-03': 1, '1.56e-02': 1, '1.62e-02': 1, '1.75e-02': 1, '1.09e-01': 2}\n",
      "\n",
      "OK\tbuild_lang_model_laplace('[Alan Ford 001 - Grupa TNT]\\n\\nNew York, najveći grad sjedinjenih država, kip slob...', 2) \n",
      "=> {'8.82e-04': 269, '1.18e-03': 80, '1.19e-03': 48, '1.22e-03': 29, '1.23e-03': 35, '1.24e-03': 26, '1.25e-03': 39, '1.26e-03': 136, '1.27e-03': 1180, '1.32e-03': 47, '1.76e-03': 20, '1.78e-03': 6, '1.79e-03': 6, '1.84e-03': 6, '1.85e-03': 2, '1.86e-03': 1, '1.87e-03': 1, '1.88e-03': 2, '1.89e-03': 9, '1.90e-03': 44, '2.21e-03': 13, '2.38e-03': 1, '2.39e-03': 2, '2.45e-03': 3, '2.46e-03': 1, '2.48e-03': 1, '2.51e-03': 1, '2.52e-03': 3, '2.53e-03': 13, '2.65e-03': 6, '2.96e-03': 2, '2.98e-03': 1, '3.09e-03': 4, '3.13e-03': 1, '3.14e-03': 1, '3.15e-03': 2, '3.16e-03': 1, '3.53e-03': 4, '3.67e-03': 1, '3.72e-03': 1, '3.75e-03': 1, '3.78e-03': 1, '3.97e-03': 4, '4.37e-03': 1, '4.41e-03': 1, '4.42e-03': 1, '4.77e-03': 1, '4.85e-03': 1, '4.96e-03': 1, '5.00e-03': 1, '5.01e-03': 1, '5.02e-03': 1, '5.36e-03': 1, '5.66e-03': 1, '5.92e-03': 1, '5.95e-03': 1, '6.55e-03': 1, '6.62e-03': 2, '6.88e-03': 1, '6.90e-03': 1, '7.06e-03': 2, '1.00e-02': 1, '1.01e-02': 1, '1.25e-02': 1}\n",
      "== {'8.82e-04': 269, '1.18e-03': 80, '1.19e-03': 48, '1.22e-03': 29, '1.23e-03': 35, '1.24e-03': 26, '1.25e-03': 39, '1.26e-03': 136, '1.27e-03': 1180, '1.32e-03': 47, '1.76e-03': 20, '1.78e-03': 6, '1.79e-03': 6, '1.84e-03': 6, '1.85e-03': 2, '1.86e-03': 1, '1.87e-03': 1, '1.88e-03': 2, '1.89e-03': 9, '1.90e-03': 44, '2.21e-03': 13, '2.38e-03': 1, '2.39e-03': 2, '2.45e-03': 3, '2.46e-03': 1, '2.48e-03': 1, '2.51e-03': 1, '2.52e-03': 3, '2.53e-03': 13, '2.65e-03': 6, '2.96e-03': 2, '2.98e-03': 1, '3.09e-03': 4, '3.13e-03': 1, '3.14e-03': 1, '3.15e-03': 2, '3.16e-03': 1, '3.53e-03': 4, '3.67e-03': 1, '3.72e-03': 1, '3.75e-03': 1, '3.78e-03': 1, '3.97e-03': 4, '4.37e-03': 1, '4.41e-03': 1, '4.42e-03': 1, '4.77e-03': 1, '4.85e-03': 1, '4.96e-03': 1, '5.00e-03': 1, '5.01e-03': 1, '5.02e-03': 1, '5.36e-03': 1, '5.66e-03': 1, '5.92e-03': 1, '5.95e-03': 1, '6.55e-03': 1, '6.62e-03': 2, '6.88e-03': 1, '6.90e-03': 1, '7.06e-03': 2, '1.00e-02': 1, '1.01e-02': 1, '1.25e-02': 1}\n",
      "\n",
      "OK\tbuild_lang_model_laplace('[Alan Ford 001 - Grupa TNT]\\n\\nNew York, najveći grad sjedinjenih država, kip slob...', 3) \n",
      "=> {'1.25e-03': 25, '1.26e-03': 72, '1.27e-03': 2461, '1.87e-03': 1, '1.88e-03': 1, '1.89e-03': 2, '1.90e-03': 44, '2.51e-03': 1, '2.52e-03': 1, '2.53e-03': 8, '3.13e-03': 1, '3.14e-03': 1, '3.15e-03': 1, '3.16e-03': 2, '4.37e-03': 1, '4.42e-03': 2, '5.02e-03': 1, '5.66e-03': 1, '5.67e-03': 1}\n",
      "== {'1.25e-03': 25, '1.26e-03': 72, '1.27e-03': 2461, '1.87e-03': 1, '1.88e-03': 1, '1.89e-03': 2, '1.90e-03': 44, '2.51e-03': 1, '2.52e-03': 1, '2.53e-03': 8, '3.13e-03': 1, '3.14e-03': 1, '3.15e-03': 1, '3.16e-03': 2, '4.37e-03': 1, '4.42e-03': 2, '5.02e-03': 1, '5.66e-03': 1, '5.67e-03': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class LangModelLaplace(dict):\n",
    "    \n",
    "    def __init__(self, txt, ngram_size):\n",
    "        self.counter_hi = count_ngrams(txt, ngram_size=ngram_size)\n",
    "        self.counter_lo = count_ngrams(txt, ngram_size=ngram_size - 1)\n",
    "        self.v = len(build_vocab(txt)) + 2\n",
    "        for ngram in self.counter_hi:\n",
    "            self[ngram] = self[ngram]\n",
    "        \n",
    "    def __getitem__(self, ngram):\n",
    "        return (self.counter_hi.get(ngram, 0) + 1) / (self.counter_lo.get(ngram[:-1], 0) + self.v)\n",
    "\n",
    "\n",
    "def build_lang_model_laplace(txt, ngram_size):\n",
    "    return LangModelLaplace(txt, ngram_size)\n",
    "\n",
    "\n",
    "testname(build_lang_model_laplace)\n",
    "\n",
    "test(build_lang_model, (\"A gdje je tvoj ured? Ne znam gdje je.\", 1), {('<sent>',): 0.15384615384615385, ('A',): 0.07692307692307693, ('gdje',): 0.15384615384615385, ('je',): 0.15384615384615385, ('tvoj',): 0.07692307692307693, ('ured',): 0.07692307692307693, ('</sent>',): 0.15384615384615385, ('Ne',): 0.07692307692307693, ('znam',): 0.07692307692307693})\n",
    "test(build_lang_model_laplace, (\"A gdje je tvoj ured? Ne znam gdje je.\", 1), {('<sent>',): 0.13636363636363635, ('A',): 0.09090909090909091, ('gdje',): 0.13636363636363635, ('je',): 0.13636363636363635, ('tvoj',): 0.09090909090909091, ('ured',): 0.09090909090909091, ('</sent>',): 0.13636363636363635, ('Ne',): 0.09090909090909091, ('znam',): 0.09090909090909091})\n",
    "\n",
    "test(build_lang_model, (\"A gdje je ured tvoj? Ne znam gdje je.\", 2), {('<sent>', 'A'): 0.5, ('A', 'gdje'): 1.0, ('gdje', 'je'): 1.0, ('je', 'ured'): 0.5, ('ured', 'tvoj'): 1.0, ('tvoj', '</sent>'): 1.0, ('<sent>', 'Ne'): 0.5, ('Ne', 'znam'): 1.0, ('znam', 'gdje'): 1.0, ('je', '</sent>'): 0.5})\n",
    "test(build_lang_model_laplace, (\"A gdje je ured tvoj? Ne znam gdje je.\", 2), {('<sent>', 'A'): 0.18181818181818182, ('A', 'gdje'): 0.2, ('gdje', 'je'): 0.2727272727272727, ('je', 'ured'): 0.18181818181818182, ('ured', 'tvoj'): 0.2, ('tvoj', '</sent>'): 0.2, ('<sent>', 'Ne'): 0.18181818181818182, ('Ne', 'znam'): 0.2, ('znam', 'gdje'): 0.2, ('je', '</sent>'): 0.18181818181818182})\n",
    "\n",
    "model_laplace1 = test_model(build_lang_model_laplace, (read_file(FILENAME), 1), {'3.18e-04': 1180, '4.76e-04': 183, '6.35e-04': 73, '7.94e-04': 44, '9.53e-04': 20, '1.11e-03': 8, '1.27e-03': 15, '1.43e-03': 13, '1.59e-03': 4, '1.75e-03': 3, '1.91e-03': 2, '2.06e-03': 3, '2.22e-03': 1, '2.38e-03': 3, '2.54e-03': 4, '2.70e-03': 2, '2.86e-03': 1, '3.02e-03': 1, '3.18e-03': 4, '3.33e-03': 1, '3.65e-03': 1, '4.45e-03': 1, '5.08e-03': 1, '5.56e-03': 1, '5.72e-03': 1, '6.51e-03': 1, '7.46e-03': 1, '7.62e-03': 1, '8.89e-03': 1, '1.56e-02': 1, '1.62e-02': 1, '1.75e-02': 1, '1.09e-01': 2})\n",
    "model_laplace2 = test_model(build_lang_model_laplace, (read_file(FILENAME), 2), {'8.82e-04': 269, '1.18e-03': 80, '1.19e-03': 48, '1.22e-03': 29, '1.23e-03': 35, '1.24e-03': 26, '1.25e-03': 39, '1.26e-03': 136, '1.27e-03': 1180, '1.32e-03': 47, '1.76e-03': 20, '1.78e-03': 6, '1.79e-03': 6, '1.84e-03': 6, '1.85e-03': 2, '1.86e-03': 1, '1.87e-03': 1, '1.88e-03': 2, '1.89e-03': 9, '1.90e-03': 44, '2.21e-03': 13, '2.38e-03': 1, '2.39e-03': 2, '2.45e-03': 3, '2.46e-03': 1, '2.48e-03': 1, '2.51e-03': 1, '2.52e-03': 3, '2.53e-03': 13, '2.65e-03': 6, '2.96e-03': 2, '2.98e-03': 1, '3.09e-03': 4, '3.13e-03': 1, '3.14e-03': 1, '3.15e-03': 2, '3.16e-03': 1, '3.53e-03': 4, '3.67e-03': 1, '3.72e-03': 1, '3.75e-03': 1, '3.78e-03': 1, '3.97e-03': 4, '4.37e-03': 1, '4.41e-03': 1, '4.42e-03': 1, '4.77e-03': 1, '4.85e-03': 1, '4.96e-03': 1, '5.00e-03': 1, '5.01e-03': 1, '5.02e-03': 1, '5.36e-03': 1, '5.66e-03': 1, '5.92e-03': 1, '5.95e-03': 1, '6.55e-03': 1, '6.62e-03': 2, '6.88e-03': 1, '6.90e-03': 1, '7.06e-03': 2, '1.00e-02': 1, '1.01e-02': 1, '1.25e-02': 1})\n",
    "model_laplace3 = test_model(build_lang_model_laplace, (read_file(FILENAME), 3), {'1.25e-03': 25, '1.26e-03': 72, '1.27e-03': 2461, '1.87e-03': 1, '1.88e-03': 1, '1.89e-03': 2, '1.90e-03': 44, '2.51e-03': 1, '2.52e-03': 1, '2.53e-03': 8, '3.13e-03': 1, '3.14e-03': 1, '3.15e-03': 1, '3.16e-03': 2, '4.37e-03': 1, '4.42e-03': 2, '5.02e-03': 1, '5.66e-03': 1, '5.67e-03': 1})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Usporedba modela "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rečenica: A gdje je tvoj ured?\n",
      "\n",
      "          model\t\tmodel_laplace\n",
      "1-gram:   1.74e-16\t8.24e-17 \n",
      "2-gram:   6.67e-06\t6.84e-17 \n",
      "3-gram:   2.27e-02\t3.21e-15 \n",
      "----------------------------------------\n",
      "Rečenica: A gdje je ured tvoj?\n",
      "\n",
      "          model\t\tmodel_laplace\n",
      "1-gram:   1.74e-16\t8.24e-17 \n",
      "2-gram:   \t\t5.70e-18 \n",
      "3-gram:   \t\t4.01e-16 \n",
      "----------------------------------------\n",
      "Rečenica: A gdje je banana?\n",
      "\n",
      "          model\t\tmodel_laplace\n",
      "1-gram:   \t\t5.77e-14 \n",
      "2-gram:   \t\t9.02e-15 \n",
      "3-gram:   \t\t6.33e-13 \n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_comparison(txt):\n",
    "    print(f\"Rečenica: {txt}\\n\")\n",
    "    print(\"          model\\t\\tmodel_laplace\")\n",
    "    for i, (model, model_laplace) in enumerate(zip([model1, model2, model3], [model_laplace1, model_laplace2, model_laplace3]), 1):\n",
    "\n",
    "        try:\n",
    "            prob = sent_prob(txt, model)\n",
    "        except:\n",
    "            prob = None\n",
    "        prob_laplace = sent_prob(txt, model_laplace)\n",
    "\n",
    "        if prob:\n",
    "            print(f\"{i}-gram:   {prob:.2e}\\t{prob_laplace:.2e} \")\n",
    "        else:\n",
    "            print(f\"{i}-gram:   \\t\\t{prob_laplace:.2e} \")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print_comparison(\"A gdje je tvoj ured?\")\n",
    "print_comparison(\"A gdje je ured tvoj?\")\n",
    "print_comparison(\"A gdje je banana?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.9 Generiranje slučajnih rečenica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alane Alane ja putujem u New York \n",
      "Upravo tako miroljubljivi \n",
      "Ne pušim\n",
      "Hm u New Yorku\n",
      "U devet sati \n",
      "Nancy je pokojnik bio policajac i dva puta da se zaista zove Alan Ford Porb ili jednih i smaragd \n",
      "Vratio sam glupa i bajoslovno vrijedni smaragd \n",
      "Odviše si zaposlena čitavu noć \n",
      "Zapamti ubijati treba golim rukama \n",
      "I možemo odmah dalje situacija je čula moj glas spustila slušalicu \n",
      "Poslije gimnastike na svježem zraku neće iznevjeriti \n",
      "Ovi su me zamijenili s nekim zamijenili \n",
      "Tebi ne brbljaj \n",
      "Ili platite ili u samostan nego što dobije brzinu \n",
      "Zaista ste Margot \n",
      "Nemam ništa jesti \n",
      "Čuo sam za rek\n",
      "Ah sat je još toga \n",
      "Ta moderna muzika zaista ono za reklamu i po \n",
      "I možemo odmah dalje situacija je težak prekršaj kopčaš \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def random_chain(model):\n",
    "    word = '<sent>'\n",
    "    sentence = []\n",
    "    while word != '</sent>':\n",
    "        next_grams = list({gram for gram in model if gram[0] == word})\n",
    "        \n",
    "        if next_grams:\n",
    "            next_gram = random.choice(next_grams)\n",
    "            sentence.append(next_gram)\n",
    "            word = next_gram[-1]\n",
    "            if word == '<sent>':\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    # print(sentence)\n",
    "    sentence = ' '.join(' '.join(gram[1:]) for gram in sentence).strip('</sent>')\n",
    "    print(sentence)\n",
    "\n",
    "for _ in range(20):\n",
    "    random_chain(model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.10. Perpleksija\n",
    "\n",
    "Inkluzivna evaluacija modela jezika se provodi perpleksijom čija je formula:\n",
    "\n",
    "$$PP(w_1, ..., w_N) = \\sqrt[N]{\\frac{1}{p(w_1)...p(w_N)}}=\\sqrt[N]{\\frac{1}{\\sum^N_1{p(w_i)}}}$$\n",
    "\n",
    "Zbog prelijeva decimalne točke, perpleksija se praktički računa u logaritamskom prostoru.\n",
    "\n",
    "$$log(PP(w_1, ..., w_N))=\\frac{-1}{N}\\sum^N_1{log(p(w_i))}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram\tPP = 9528.02408134646\n",
      "2-gram\tPP = 9997.350460129475\n",
      "3-gram\tPP = 2878.8639045661016\n",
      "4-gram\tPP = 731.6622279029574\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def perplexity(txt, model):\n",
    "    ngram_size = len(next(iter(model)))\n",
    "\n",
    "    vocab_size = len(build_vocab(txt))    \n",
    "    p = 0\n",
    "    for sent in segment_sent(txt):\n",
    "        for ngram in build_sent_ngram(sent, ngram_size):\n",
    "            pi = model[ngram]\n",
    "            p += math.log(pi)    \n",
    "\n",
    "    pp = (-1 / vocab_size) * p\n",
    "    return math.exp(pp)\n",
    "        \n",
    "test_txt = \"\"\"\n",
    "Bio bih sretan \n",
    "Kakve su policajci \n",
    "Jedino nedostaje mikrofilm a sad evo me čuj momče \n",
    "Ali to je mnogo struju \n",
    "Hvala mladiću \n",
    "Prava pravcata mušterija advokata i tu piše \n",
    "Mister Ford \n",
    "Zovem je sinko \n",
    "Prljavi izdajniče \n",
    "Nešto u posljednji čas Miss \n",
    "Palm Beach je čim je grad pun nevaljalaca \n",
    "Želiš li razočaranja \n",
    "New York \n",
    "Stare su nas \n",
    "Razumije se rezervacija za kandidata smrti \n",
    "Znam malajski trik za početak poslije ću ti ja se prljavi štakore \n",
    "Kod nje je naša blagajna punija \n",
    "Moramo hitno u dnevnom tisku za početak poslije ću zadržati za petama žutokljunče \n",
    "Glupane \n",
    "Oprosti na stvari \n",
    "\"\"\"\n",
    "    \n",
    "train_txt = read_file(FILENAME)\n",
    "\n",
    "for ngram_size in range(1, 5):\n",
    "    model = build_lang_model_laplace(train_txt, ngram_size)\n",
    "    pp = perplexity(test_txt,  model)\n",
    "    print(f\"{ngram_size}-gram\\tPP = {pp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "358f19b5168dcc2c817c22e8ae2c189228565b53de3b91095ee770a390daccdd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
